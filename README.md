# Benchmark App

A FastAPI benchmark tool that compares async vs sync database operations with SQLite. Tests three approaches: pure async, sync in threadpool, and sync blocking.

> **Note**: This benchmark code was generated by AI for testing purposes.

## Quick Start

### Prerequisites
- **Vegeta**: HTTP load testing tool required for benchmarking
  - Install: [https://github.com/tsenart/vegeta#install](https://github.com/tsenart/vegeta#install)
  - Or via Homebrew: `brew install vegeta`

### Install
```bash
uv sync  # or pip install -e .
```

### Run
```bash
# Default: 50, 100, 200 RPS for 10s each
python run_benchmark.py

# Custom rates and duration
python run_benchmark.py --rates 25 50 100 --duration 15s

# Test with multiple workers
python run_benchmark.py --workers 4 --rates 100 200 300
```

### Plot Results
```bash
# Generate ASCII charts, tables, and HTML report (default)
python plot_results.py

# Skip HTML generation (ASCII only)
python plot_results.py --no-html

# Use specific benchmark directory
python plot_results.py --dir .tmp/bench_20250909_123456

# Custom HTML output filename
python plot_results.py --output my_report.html
```

### Options
- `--rates`: RPS to test (default: `50 100 200`)
- `--host`: Server host (default: `127.0.0.1`)
- `--port`: Server port (default: `8000`)
- `--duration`: Test duration (default: `10s`)
- `--workers`: Number of uvicorn worker processes (default: `1`)

## What It Tests

The benchmark automatically discovers and tests all endpoints in `bench_endpoints.py`. Current endpoints:

| Endpoint | Description | Use Case |
|----------|-------------|----------|
| `get_item_async` | Pure async with `aiosqlite` | IO bound operations |
| `get_item_sync_threadpool` | Sync DB in threadpool | CPU bound operations |
| `get_item_sync_blocking` | Sync DB blocks event loop | ‚ùå What NOT to do? |

**Auto-discovery**: Add new endpoints to `bench_endpoints.py` and they'll be automatically included in benchmarks!

## Visualization

The benchmark includes comprehensive visualization tools:

### ASCII Charts
- **Performance metrics**: RPS, latency (P50, P95, P99), success rates
- **Resource usage**: CPU and memory consumption
- **Comparison**: Side-by-side endpoint performance

### Interactive HTML Reports (Default)
- **Chart.js graphs**: Interactive line charts for all metrics
- **Performance trends**: How metrics change with load
- **Resource analysis**: CPU and memory usage patterns
- **Detailed tables**: Complete results with formatting
- **Export ready**: Professional reports for presentations
- **Clickable links**: Console output includes direct file links

### Chart Types
- **Achieved RPS vs Target Rate**: Shows actual throughput performance
- **Latency vs Target Rate**: Reveals performance degradation patterns
- **Success Rate vs Target Rate**: Identifies breaking points
- **CPU Usage vs Target Rate**: Resource efficiency analysis
- **Memory Usage vs Target Rate**: Memory consumption patterns

## Metrics Explained

### Success Rate
- **What**: % of requests that return HTTP 200
- **Formula**: `(Successful / Total) √ó 100`
- **Why**: Shows how well each approach handles load

### Achieved RPS
- **What**: Actual throughput the server delivers
- **Formula**: `Successful Requests / Test Duration`
- **Why**: Real capacity, not just target rate

### Latency (P50, P95, P99)
- **P50**: 50% of requests complete within this time
- **P95**: 95% of requests complete within this time
- **P99**: 99% of requests complete within this time
- **Why**: Lower = better user experience

### CPU Usage
- **What**: Server process CPU consumption
- **How**: Samples every 0.5s using `ps` command
- **Why**: Lower = more efficient, can handle more load

## Sample Output

```
üìà Rate 100 RPS:
Endpoint     Target Achieved P50(ms)  P95(ms)  Success% CPU Avg%
----------------------------------------------------------------
async        100    98.5     3.2      6.1      98.5     28.4    
sync_tp      100    95.2     4.1      8.3      95.2     35.1    
sync_block   100    45.3     12.8     25.4     45.3     45.8    
```

## Expected Results

- **Low loads (< 50 RPS)**: All approaches similar
- **Medium loads (50-100 RPS)**: Async starts winning
- **High loads (> 100 RPS)**: Sync blocking fails, async scales best

## Prerequisites

- Python 3.10+
- [Vegeta](https://github.com/tsenart/vegeta): `brew install vegeta`
- `uv` or `pip`

## Troubleshooting

**"Server failed to start"**
```bash
# Check if port is in use
lsof -i :8000
# Kill existing process
pkill -f uvicorn
```

**"Vegeta not found"**
```bash
# macOS
brew install vegeta
# Or download from GitHub releases
```

**"Low success rates"**
- This is expected - shows the breaking point
- Try lower RPS rates to see where each approach works

## Output Files

Results saved to `.tmp/bench_YYYYMMDD_HHMMSS/`:
- `fast_cpu_results.json` - Complete data
- `{endpoint}_{rate}.json` - Individual test results
- `{endpoint}_{rate}_cpu.json` - CPU monitoring data

## Architecture

### Endpoints
- `GET /api/bench/items/{id}` - Async DB query
- `GET /api/bench/items-sync-threadpool/{id}` - Sync in threadpool
- `GET /api/bench/items-sync-blocking/{id}` - Sync blocking
- `POST /api/bench/seed` - Seed test data

### Database
- SQLite with WAL mode for concurrency
- 2000 test records (items 1-2000)
- Same DB file for all approaches

## Use Cases

- **Performance comparison** between async/sync patterns
- **Capacity planning** for production
- **Load testing** database access patterns
- **CPU efficiency analysis** for cost optimization
