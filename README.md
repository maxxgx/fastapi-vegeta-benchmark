# FastAPI Vegeta Benchmark

A comprehensive FastAPI benchmark tool that compares async vs sync database operations with SQLite. Tests multiple approaches: pure async, sync in threadpool, and sync blocking patterns for both read and write operations.

> **Note**: This benchmark code was generated by AI for testing purposes.

## Quick Start

### Prerequisites
- **Vegeta**: HTTP load testing tool required for benchmarking
  - Install: [https://github.com/tsenart/vegeta#install](https://github.com/tsenart/vegeta#install)
  - Or via Homebrew: `brew install vegeta`

### Install
```bash
uv sync  # or pip install -e .
```

### Run
```bash
# Default: 1000, 2000 RPS for 10s each
python run_benchmark.py

# Custom rates and duration
python run_benchmark.py --rates 1250 2500 --duration 15s

# Test with multiple workers
python run_benchmark.py --workers 4 --rates 1000

# Test only simple endpoints
python run_benchmark.py --filter /api/simple --rates 10

# Test only specific endpoint patterns
python run_benchmark.py --filter /api/simple/sync --workers 8
```

### Plot Results
```bash
# Generate ASCII charts, tables, and HTML report (default)
python plot_results.py

# Skip HTML generation (ASCII only)
python plot_results.py --no-html

# Use specific benchmark directory
python plot_results.py --dir .tmp/bench_20250909_123456

# Custom HTML output filename
python plot_results.py --output my_report.html
```

### Options
- `--rates`: RPS to test (default: `1000 2000`)
- `--host`: Server host (default: `127.0.0.1`)
- `--port`: Server port (default: `8000`)
- `--duration`: Test duration (default: `10s`)
- `--workers`: Number of uvicorn worker processes (default: `1`)
- `--filter`: Filter endpoints by path prefix (e.g., `/api/simple` for simple endpoints only)

## What It Tests

The benchmark automatically discovers and tests all GET and POST endpoints in your FastAPI app. Current endpoints:

### Simple Endpoints (`/api/simple/*`)
| Endpoint | Description | Use Case |
|----------|-------------|----------|
| `GET /sync_threadpool/{item_id}` | Sync with blocking sleep | Tests worker scaling |
| `GET /async_blocking/{item_id}` | Async with blocking sleep | ‚ùå Demonstrates blocking problems |
| `GET /async/{item_id}` | Async with non-blocking sleep | Tests async concurrency |

### Database Endpoints (`/api/db/*`)
| Endpoint | Description | Use Case |
|----------|-------------|----------|
| `GET /async/read/{item_id}` | Pure async read with `aiosqlite` | IO bound read operations |
| `POST /async/write/{item_id}` | Pure async write with `aiosqlite` | IO bound write operations |
| `GET /sync_threadpool/read/{item_id}` | Sync DB read in threadpool | CPU bound read operations |
| `POST /sync_threadpool/write/{item_id}` | Sync DB write in threadpool | CPU bound write operations |
| `GET /async/blocking/read/{item_id}` | Async with blocking DB read | ‚ùå blocking SQLite read |
| `POST /async/blocking/write/{item_id}` | Async with blocking DB write | ‚ùå blocking SQLite write |
| `POST /seed` | Seed test data | Database initialization |

**Auto-discovery**: Add new endpoints and they'll be automatically included in benchmarks!
**Filtering**: Use `--filter /api/simple` or `--filter /api/db` to test only specific endpoint groups.

## Visualization

The benchmark includes comprehensive visualization tools:

### ASCII Charts
- **Performance metrics**: RPS, latency (P50, P95, P99), success rates
- **Resource usage**: CPU and memory consumption
- **Comparison**: Side-by-side endpoint performance

### Interactive HTML Reports (Default)
- **Chart.js graphs**: Interactive line charts for all metrics
- **Performance trends**: How metrics change with load
- **Resource analysis**: CPU and memory usage patterns
- **Detailed tables**: Complete results with formatting
- **Export ready**: Professional reports for presentations
- **Clickable links**: Console output includes direct file links

### Chart Types
- **Achieved RPS vs Target Rate**: Shows actual throughput performance
- **Latency vs Target Rate**: Reveals performance degradation patterns
- **Success Rate vs Target Rate**: Identifies breaking points
- **CPU Usage vs Target Rate**: Resource efficiency analysis
- **Memory Usage vs Target Rate**: Memory consumption patterns

## Metrics Explained

### Success Rate
- **What**: % of requests that return HTTP 200
- **Formula**: `(Successful / Total) √ó 100`
- **Why**: Shows how well each approach handles load

### Achieved RPS
- **What**: Actual throughput the server delivers
- **Formula**: `Successful Requests / Test Duration`
- **Why**: Real capacity, not just target rate

### Latency (P50, P95, P99)
- **P50**: 50% of requests complete within this time
- **P95**: 95% of requests complete within this time
- **P99**: 99% of requests complete within this time
- **Why**: Lower = better user experience

### CPU Usage
- **What**: Server process CPU consumption
- **How**: Samples every 0.5s using `ps` command
- **Why**: Lower = more efficient, can handle more load

## Sample Output

```
üìà Rate 2000 RPS:
Endpoint                            Target Achieved P50(ms)  Avg(ms)  P95(ms)  Success% CPU Avg%
-------------------------------------------------------------------------------------------------
simple_async                        2000   2000.0   50.3     50.3     51.4     100.0    29.0    
simple_sync_threadpool              2000   262.9    10000.1  8497.6   10000.1  13.2     38.3    
simple_async_blocking               2000   12.6     227.5    621.3    1468.1   0.6      0.5     
get_item_async_read                 2000   2000.0   0.7      4.6      25.0     100.0    66.1    
update_item_async_write             2000   1843.3   8415.0   6767.4   10000.1  92.2     82.4    
get_item_sync_threadpool_read       2000   1157.5   345.0    1090.7   5547.5   59.3     93.9    
update_item_sync_threadpool_write   2000   1393.8   5709.0   4852.7   9465.6   69.7     147.3   
get_item_async_blocking_read        2000   463.3    62.6     557.3    6146.3   26.2     19.1    
update_item_async_blocking_write    2000   884.3    5715.9   4773.1   10000.1  44.6     57.1    
```

## Prerequisites

- Python 3.10+
- [Vegeta](https://github.com/tsenart/vegeta): `brew install vegeta`
- `uv` or `pip`

## Troubleshooting

**"Server failed to start"**
```bash
# Check if port is in use
lsof -i :8000
# Kill existing process
pkill -f uvicorn
```

**"Vegeta not found"**
```bash
# macOS
brew install vegeta
# Or download from GitHub releases
```

**"Low success rates"**
- This is expected - shows the breaking point
- Try lower RPS rates to see where each approach works

## Output Files

Results saved to `.tmp/bench_YYYYMMDD_HHMMSS/`:
- `fast_cpu_results.json` - Complete data
- `{endpoint}_{rate}.json` - Individual test results
- `{endpoint}_{rate}_cpu.json` - CPU monitoring data

## Architecture

### Endpoints
- **Simple Endpoints** (`/api/simple/*`):
  - `GET /sync_threadpool/{item_id}` - Sync with blocking sleep
  - `GET /async_blocking/{item_id}` - Async with blocking sleep (anti-pattern)
  - `GET /async/{item_id}` - Proper async with non-blocking sleep

- **Database Endpoints** (`/api/db/*`):
  - `GET /async/read/{item_id}` - Pure async database read
  - `POST /async/write/{item_id}` - Pure async database write
  - `GET /sync_threadpool/read/{item_id}` - Sync database read in threadpool
  - `POST /sync_threadpool/write/{item_id}` - Sync database write in threadpool
  - `GET /async/blocking/read/{item_id}` - Async with blocking database read (anti-pattern)
  - `POST /async/blocking/write/{item_id}` - Async with blocking database write (anti-pattern)
  - `POST /seed` - Seed test data

### Database
- SQLite with WAL mode for concurrency
- 2000 test records (items 1-2000) in `bench_items` table
- Same DB file for all approaches
- Uses `aiosqlite` for async operations and `sqlite3` for sync operations

### Database Schema
```sql
CREATE TABLE bench_items (
    id INTEGER PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    value INTEGER NOT NULL
);
```

### Key Features
- **Auto-discovery**: Automatically finds and tests all GET/POST endpoints
- **Comprehensive testing**: Both read and write operations
- **Real-world patterns**: Demonstrates proper async vs common anti-patterns
- **Worker scaling**: Tests how different approaches scale with multiple workers
- **Resource monitoring**: Tracks CPU and memory usage during tests
- **Visualization**: Generates both ASCII charts and interactive HTML reports

## Use Cases


- **Performance comparison** between async/sync patterns for both read and write operations
- **Capacity planning** for production database workloads
- **Load testing** database access patterns under various concurrency models
- **CPU efficiency analysis** for cost optimization
- **Worker scaling analysis** to determine optimal worker counts
- **Anti-pattern detection** to identify common async programming mistakes
- **Database concurrency testing** with SQLite WAL mode
